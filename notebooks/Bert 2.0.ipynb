{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_scheduler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # для прогрес-бару\n",
    "\n",
    "# --- 0. Налаштування та визначення пристрою ---\n",
    "print(\"--- 0. Setup and Device Configuration ---\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Завантаження та очищення даних ---\n",
    "print(\"\\n--- 1. Data Loading and Cleaning ---\")\n",
    "# train_df_raw = pd.read_csv('../data/liar/train_filtered.csv')\n",
    "# val_df_raw = pd.read_csv('../data/liar/valid_filtered.csv')\n",
    "# test_df_raw = pd.read_csv('../data/liar/test_filtered.csv')\n",
    "\n",
    "train_df_raw = pd.read_csv('../data/fakenewsnet_dataset/combined_train.csv')\n",
    "val_df_raw = pd.read_csv('../data/fakenewsnet_dataset/combined_val.csv')\n",
    "test_df_raw = pd.read_csv('../data/fakenewsnet_dataset/combined_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def clean_dataframe(df, text_column='statement', label_column='binary_label'):\n",
    "    print(f\"Initial shape for {df.name if hasattr(df, 'name') else 'DataFrame'}: {df.shape}\")\n",
    "    df.dropna(subset=[text_column], inplace=True)\n",
    "    df = df[df[text_column].apply(lambda x: isinstance(x, str) and x.strip() != '')].copy() # Додано .copy() для уникнення SettingWithCopyWarning\n",
    "    print(f\"Shape after cleaning: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "train_df_raw.name = 'Train_Raw' # Для логування\n",
    "val_df_raw.name = 'Val_Raw'\n",
    "test_df_raw.name = 'Test_Raw'\n",
    "\n",
    "train_df = clean_dataframe(train_df_raw)\n",
    "val_df = clean_dataframe(val_df_raw)\n",
    "test_df = clean_dataframe(test_df_raw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Ініціалізація токенізатора BERT ---\n",
    "print(\"\\n--- 2. BERT Tokenizer Initialization ---\")\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# --- 3. Створення класу Dataset ---\n",
    "print(\"\\n--- 3. Custom Dataset Class ---\")\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = texts.tolist() # Перетворюємо на список для індексації\n",
    "        self.labels = labels.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True, # Додає [CLS] та [SEP]\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'  # Повертає PyTorch тензори\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "MAX_LEN = 256 # Максимальна довжина послідовності для BERT\n",
    "train_dataset = NewsDataset(train_df['statement'], train_df['binary_label'], tokenizer, MAX_LEN)\n",
    "val_dataset = NewsDataset(val_df['statement'], val_df['binary_label'], tokenizer, MAX_LEN)\n",
    "test_dataset = NewsDataset(test_df['statement'], test_df['binary_label'], tokenizer, MAX_LEN)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. Створення DataLoader'ів ---\n",
    "print(\"\\n--- 4. DataLoaders Creation ---\")\n",
    "BATCH_SIZE = 16 # Розмір батчу\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- 5. Завантаження моделі BERT ---\n",
    "print(\"\\n--- 5. BERT Model Loading ---\")\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # 2 класи: фейк/правда\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- 6. Optimizer and Scheduler Setup ---\")\n",
    "LEARNING_RATE = 2e-5\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "NUM_EPOCHS = 5 # Кількість епох\n",
    "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", # Тип планувальника\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0, # Кількість кроків для \"розігріву\"\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# --- 7. Функція для оцінки на валідаційній вибірці ---\n",
    "def evaluate_model_on_val(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            labels = batch['labels']\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(data_loader)\n",
    "    val_accuracy = correct_predictions.double() / total_predictions\n",
    "\n",
    "    # Розрахунок F1 для валідації\n",
    "    val_f1 = classification_report(all_val_labels, all_val_preds, output_dict=True, zero_division=0)['weighted avg']['f1-score']\n",
    "\n",
    "    return avg_val_loss, val_accuracy.item(), val_f1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# --- 8. Цикл навчання моделі ---\n",
    "print(\"\\n--- 8. Model Training Loop ---\")\n",
    "best_val_f1 = -1 # Для збереження найкращої моделі за F1 на валідації\n",
    "history_bert = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': [], 'val_f1': []}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train_predictions = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}', leave=True)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Розрахунок точності на тренувальному батчі (опціонально, для моніторингу)\n",
    "        logits_train = outputs.logits\n",
    "        preds_train = torch.argmax(logits_train, dim=1)\n",
    "        correct_train_predictions += torch.sum(preds_train == batch['labels'])\n",
    "        total_train_samples += batch['labels'].size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Градієнтний кліппінг\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train_predictions.double() / total_train_samples\n",
    "    history_bert['train_loss'].append(avg_train_loss)\n",
    "    history_bert['train_accuracy'].append(train_accuracy.item())\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} - Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Оцінка на валідаційній вибірці\n",
    "    avg_val_loss, val_accuracy, val_f1 = evaluate_model_on_val(model, val_loader, device)\n",
    "    history_bert['val_loss'].append(avg_val_loss)\n",
    "    history_bert['val_accuracy'].append(val_accuracy)\n",
    "    history_bert['val_f1'].append(val_f1)\n",
    "    print(f\"Epoch {epoch+1} - Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    # Збереження найкращої моделі\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        # Зберігаємо модель (рекомендований спосіб для Hugging Face)\n",
    "        model.save_pretrained('./bert_classifier_liar_best_model/')\n",
    "        tokenizer.save_pretrained('./bert_classifier_liar_best_model/') # Зберігаємо і токенізатор\n",
    "        print(f\"Epoch {epoch+1}: Best model saved with Val F1: {val_f1:.4f}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Завантаження найкращої моделі для фінальної оцінки\n",
    "print(\"\\nLoading best model for final evaluation...\")\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_classifier_liar_best_model/')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# --- 9. Графіки історії навчання ---\n",
    "print(\"\\n--- 9. Plotting Training History ---\")\n",
    "def plot_bert_history(history):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('BERT Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('BERT Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history['val_f1'], label='Validation F1-Score')\n",
    "    plt.title('BERT Model Validation F1-Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_bert_history(history_bert)\n",
    "\n",
    "history_df = pd.DataFrame({\n",
    "    'Epoch': range(1, len(history_bert['train_accuracy']) + 1),\n",
    "    'Train Accuracy': history_bert['train_accuracy'],\n",
    "    'Validation Accuracy': history_bert['val_accuracy'],\n",
    "    'Train Loss': history_bert['train_loss'],\n",
    "    'Validation Loss': history_bert['val_loss'],\n",
    "    'Validation F1': history_bert['val_f1']\n",
    "})\n",
    "\n",
    "# Виведення таблиці\n",
    "print(history_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# --- 10. Оцінка моделі на тестовій вибірці ---\n",
    "print(\"\\n--- 10. Final Evaluation on Test Set ---\")\n",
    "model.eval() # Переводимо модель в режим оцінки\n",
    "all_test_preds = []\n",
    "all_test_probs = []\n",
    "all_test_labels = []\n",
    "\n",
    "with torch.no_grad(): # Відключаємо обчислення градієнтів\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        # Отримуємо ймовірності для позитивного класу\n",
    "        probs = torch.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
    "        # Отримуємо прогнозовані класи\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "        all_test_probs.extend(probs)\n",
    "        all_test_preds.extend(preds)\n",
    "        all_test_labels.extend(labels)\n",
    "\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(all_test_labels, all_test_preds, zero_division=0))\n",
    "\n",
    "# Матриця помилок\n",
    "cm_test_bert = confusion_matrix(all_test_labels, all_test_preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_test_bert, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('BERT Confusion Matrix (Test Set)')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# ROC-крива\n",
    "fpr_test_bert, tpr_test_bert, _ = roc_curve(all_test_labels, all_test_probs)\n",
    "roc_auc_test_bert = auc(fpr_test_bert, tpr_test_bert)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(fpr_test_bert, tpr_test_bert, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc_test_bert:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('BERT ROC Curve (Test Set)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"BERT Model Test AUC: {roc_auc_test_bert:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
